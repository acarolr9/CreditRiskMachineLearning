# Predicci√≥n del riesgo crediticio con impacto sostenible

**ABSTRACT**

This work focuses on addressing deficiencies in the risk prediction model for natural customers of ALFA Colombia. Currently, this model classifies approximately 53% of customers as high probability of default, despite the real default rate in risk entities being only 5%. This directly affects two strategic objectives of ALFA Colombia: growing in customers and efficiently applying data and technology.

The general objective of the project is to develop a new scoring model for the segment of customers who domicile their payroll and pension in the bank, in order to replace the existing model and provide support in credit pre-approval, risk monitoring, and provision calculation.

To achieve this objective, the organization's database of variables and customer transactional information will be utilized. Additionally, the inclusion of social network analysis using customer transactions will be explored to assess how they impact payment behavior and enhance the predictive capacity of the model. Other estimation methodologies that can provide more accurate predictions will also be tested, evaluated through the Gini index.

Finally, the energy efficiency of each proposed model will be analyzed to align it with the company's sustainable vision. A cost-benefit analysis will be conducted to justify the sustainability of the proposal.

In summary, this project aims to improve the risk prediction model of ALFA Colombia by developing a new scoring model, incorporating social network analysis, and evaluating other estimation methodologies. Additionally, the energy efficiency of each proposed model will be considered.

**RESUMEN**

Este trabajo se centra en abordar las deficiencias en el modelo de predicci√≥n de riesgo para clientes naturales de ALFA Colombia. Actualmente, este modelo clasifica aproximadamente al 53% de los clientes como alta probabilidad de impago, a pesar de que la tasa de mora en entidades de riesgo real es solo del 5%. Esto afecta directamente a dos objetivos estrat√©gicos de ALFA Colombia: crecer en clientes y aplicar eficientemente los datos y la tecnolog√≠a.

El objetivo general del proyecto es desarrollar un nuevo modelo de scoring para el segmento de clientes que domicilian n√≥mina y pensi√≥n en el banco, con el fin de reemplazar el modelo existente y brindar soporte en la preconcesi√≥n de cr√©ditos, seguimiento del riesgo y c√°lculo de provisiones.

Para lograr este objetivo, se utilizar√° la base de datos de variables de la organizaci√≥n y la informaci√≥n de transaccionalidad de los clientes. Adem√°s, se explorar√° la inclusi√≥n del an√°lisis de redes sociales utilizando las transacciones de los clientes para evaluar c√≥mo afectan el comportamiento de pago y mejoran la capacidad predictiva del modelo. Tambi√©n se probar√°n otras metodolog√≠as de estimaci√≥n que puedan proporcionar predicciones m√°s precisas, evaluadas a trav√©s del √≠ndice Gini.

Finalmente, se analizar√° la eficiencia energ√©tica de cada modelo propuesto para alinearlo con la visi√≥n sostenible de la compa√±√≠a. Se realizar√° un an√°lisis de costo-beneficio para justificar la sostenibilidad de la propuesta.

En resumen, este proyecto busca mejorar el modelo de predicci√≥n de riesgo de ALFA Colombia mediante el desarrollo de un nuevo modelo de scoring, la inclusi√≥n del an√°lisis de redes sociales y la evaluaci√≥n de otras metodolog√≠as de estimaci√≥n. Adem√°s, se considerar√° la eficiencia energ√©tica de cada modelo propuesto.

\*
# <a name="_toc428793005"></a><a name="_toc151738696"></a><a name="_toc512935102"></a>Introducci√≥n
ALFA Colombia es una entidad bancaria con presencia en m√°s de 122 municipios a lo largo del territorio nacional, que se rige con base en seis prioridades estrat√©gicas buscando la transformaci√≥n del Grupo y el logro de su prop√≥sito: ‚ÄòPoner al alcance de todos las oportunidades de la nueva era‚Äô. (ALFA, 2022)

1\.	Mejorar la salud financiera de nuestros clientes

2\.	Ayudar a nuestros clientes en la transici√≥n hacia un futuro sostenible

3\.	Crecer en clientes

4\.	Buscar la excelencia operativa

5\.	El mejor equipo y el m√°s comprometido

6\.	Datos y tecnolog√≠a

Sin embargo, con el objetivo de cumplir estos pilares estrat√©gicos en Colombia, se han detectado altas deficiencias en el modelo de predicci√≥n de riesgo para clientes naturales, lo cual est√° provocando que aproximadamente el 53% de los clientes sean clasificados con alta probabilidad de impago, mientras que la tasa de mora en entidades de riesgo real es solo de aproximadamente el 5% (Experian, 2022). Esto afecta directamente dos de los objetivos discutidos anteriormente: el primero es el crecimiento en clientes, ya que hay muchos clientes potenciales que no son bien calificados por el modelo, y el segundo es la adecuada aplicaci√≥n de datos y tecnolog√≠a, que est√° ausente en el modelo actual.
# <a name="_toc428793006"></a><a name="_toc151738697"></a>1. Descripci√≥n general
## <a name="_toc428793007"></a><a name="_toc151738698"></a>1.1 Oportunidad y problem√°tica
Con el fin de dar soluci√≥n a la problem√°tica la idea del proyecto es utilizar la base de datos de variables  de la organizaci√≥n y la informaci√≥n de transaccionalidad  de los clientes para construir un modelo de predicci√≥n de incumplimiento. El modelo se utilizar√° con dos prop√≥sitos: primero, para ofrecer nuevos productos a los clientes actuales; segundo, para estimar la probabilidad de incumplimiento en el c√°lculo de la provisi√≥n para los clientes ya vinculados.

Sin embargo, dado que la entidad ya ha desarrollado un modelo basado en regresi√≥n log√≠stica, y la informaci√≥n utilizada para su construcci√≥n es la misma que estar√° disponible para la estimaci√≥n del nuevo modelo, se explorar√° la inclusi√≥n del an√°lisis de redes sociales (SNA) utilizando las transacciones de los clientes. El objetivo es evaluar c√≥mo la centralidad de un nodo, la fuerza de sus relaciones y otras m√©tricas del an√°lisis afectan el comportamiento de pago y mejoran la capacidad predictiva del modelo (√ìskarsd√≥ttir & Bravo, 2021). Adem√°s, se plantear√° la prueba de otras metodolog√≠as de estimaci√≥n que puedan proporcionar predicciones m√°s precisas, las cuales ser√°n evaluadas a trav√©s del √≠ndice Gini del modelo.

<a name="_toc428793009"></a>Finalmente, con el fin de abordar otro de los pilares estrat√©gicos de la compa√±√≠a y darle una perspectiva m√°s sostenible a la soluci√≥n planteada, se analizar√° la eficiencia energ√©tica de cada modelo para que la propuesta no solo genere mejores indicadores de predicci√≥n, sino que tambi√©n se alinee con la visi√≥n sostenible de la compa√±√≠a.
## <a name="_toc151738699"></a>1.2 Objetivo general
Desarrollar un modelo de scoring para el segmento de clientes que domicilian n√≥mina y pensi√≥n en el banco (vinculado), que permita reemplazar al vigente y brinde soporte tanto para la preconcesi√≥n de cr√©ditos como para el seguimiento del riesgo y el c√°lculo de par√°metros para el consumo de provisiones en funci√≥n de la probabilidad de mora.
## <a name="_toc428793010"></a><a name="_toc151738700"></a>1.3 Objetivos espec√≠ficos
\- Evaluar la situaci√≥n actual del banco y determinar la problem√°tica que atacara el proyecto.

\- Realizar an√°lisis de redes utilizando la informaci√≥n de transacciones.

\- Desarrollar y evaluar diversos modelos de predicci√≥n del comportamiento de pago del cliente.

\- Analizar la eficiencia energ√©tica de cada modelo propuesto.
# <a name="_toc151738701"></a><a name="_toc428793017"></a>2. Marco te√≥rico 
El sector financiero en Colombia se caracteriza por tener m√°s de $1.600 billones en activos y 415 entidades (El Tiempo, 2017), las cuales son organizaciones o instituciones, tanto p√∫blicas como privadas. A trav√©s de ellas se captan, administran, regulan y dirigen los recursos financieros que se negocian entre los diversos agentes econ√≥micos, ya sean personas, empresas, el Estado y/o el sector p√∫blico. Estas entidades pueden clasificarse como entidades de cr√©dito, sociedades de servicios financieros y otros establecimientos que agrupan diversas l√≠neas de negocio, como se aprecia a continuaci√≥n (Escuela Nacional Sindical, 2015).

![](001.png)

**Ilustraci√≥n 1:** Tipos de establecimientos financieros tomado de **(Asobancaria, 2021)** 

Para el desarrollo de este proyecto, el estudio se centrar√° en comprender los establecimientos de cr√©dito, que tienen como funci√≥n la captaci√≥n de recursos del p√∫blico en moneda legal a trav√©s de dep√≥sitos a la vista o a t√©rmino. Estos recursos se destinan para su posterior colocaci√≥n mediante pr√©stamos, descuentos, anticipos u otras operaciones relacionadas con el cr√©dito (Asobancaria, 2021), enfoc√°ndonos en el an√°lisis de entidades bancarias. Estas son empresas financieras encargadas de captar recursos en forma de dep√≥sitos y otorgar pr√©stamos, adem√°s de ofrecer una variedad de servicios financieros a trav√©s de sus diversas filiales.

Dentro de este contexto, las entidades bancarias operan con base en portafolios de productos compuestos principalmente por cuentas de ahorros, cuentas corrientes, cr√©ditos y tarjetas de cr√©dito. Seg√∫n el reporte de tipificaci√≥n de Asobancaria para el segundo trimestre del a√±o 2021, en Colombia, el 89,5% de la poblaci√≥n adulta, conformada por personas mayores de edad, cuenta con al menos un producto financiero.

Asimismo, el sector financiero colombiano est√° dominado por unos pocos grupos financieros. Estos, a trav√©s de sus conglomerados de empresas, ofrecen un amplio portafolio de servicios que abarcan desde servicios bancarios, seguros y administraci√≥n de valores, hasta la gesti√≥n de fondos de inversi√≥n, pensiones y cesant√≠as, entre otros. Dos de estos grupos lideran el mercado con una participaci√≥n de aproximadamente el 40% en las diferentes l√≠neas de cr√©dito.

![](002.png) ![](003.png)

![](004.png)

**Ilustraci√≥n 2:** Participaci√≥n en el mercado de los bancos en Colombia. Tomado de **(Asobancaria, 2021)**
## <a name="_toc151738702"></a>2.1 Scoring Bancario
El puntaje de cr√©dito, tambi√©n conocido como score, es una calificaci√≥n que determina la probabilidad de que una persona cumpla con sus obligaciones financieras. Esta evaluaci√≥n se basa en su historial crediticio, el uso y saldo de sus cr√©ditos, y otras variables sociodemogr√°ficas. En Colombia, empresas como DataCredito, Experian o TransUnion ofrecen canales de consulta para obtener este puntaje, que tiene un rango de 150 a 950 puntos. Cuanto m√°s alto sea el puntaje, mayores ser√°n las posibilidades de obtener un cr√©dito, ya que representa un menor riesgo para las entidades financieras (El Tiempo, 2017).

Este concepto ha evolucionado para convertirse en una herramienta de apoyo a las actividades del analista de cr√©dito. Los puntajes se utilizan para determinar factores de riesgo que se someter√°n a evaluaci√≥n, y con base en la informaci√≥n recopilada, se realiza un an√°lisis para aprobar o denegar una solicitud. As√≠, el Scoring se define como la implementaci√≥n de sistemas de evaluaci√≥n de riesgo financiero basados en t√©cnicas de inteligencia artificial o "big data" (Ospina D√≠az, 2017). Esta herramienta lleva los an√°lisis de riesgo m√°s all√° de los reportes en centrales de riesgo hasta incluir informaci√≥n de las redes sociales.

En entidades bancarias, el Scoring se utiliza ampliamente en el cr√©dito al consumo dirigido a particulares, tarjetas de cr√©dito e hipotecas de vivienda, como se√±ala Oriol Amat. Seg√∫n datos de Fair Isaac Company, m√°s del 75% de las entidades de cr√©dito lo utilizan para la concesi√≥n de hipotecas y m√°s del 90% lo emplean para tarjetas de cr√©dito. Empresas como Equifax, Experian, TransUnion y Axesor suministran informes sobre clientes basados en scorings.

El Scoring se realiza a trav√©s del an√°lisis discriminante, que consta de dos etapas:

**Primera etapa (An√°lisis factorial discriminante):** El objetivo de esta etapa es identificar las variables que se utilizar√°n en el sistema de puntuaci√≥n. Para ello, se necesita un conjunto de prestatarios que integran la muestra a utilizar y se definir√°n los comportamientos de los que se quieren formular predicciones (pago puntual de los cr√©ditos o impago de los cr√©ditos). As√≠ como, es estado final de los clientes cumplimiento o incumplimiento (Oriol, 2014)

Tambi√©n se encuentra que las caracter√≠sticas que discriminan m√°s suelen ser de tipo personal (edad, n√∫mero de hijos‚Ä¶), socioecon√≥micas (situaci√≥n laboral, tipo de contrato laboral, a√±os de antig√ºedad en la empresa, barrio de residencia‚Ä¶) y financieras (ingresos, vivienda, patrimonio, titularidad de otros pr√©stamos, historial de pagos con la entidad, incidencias de morosidad‚Ä¶). Hay informaciones de tipo personal que en determinados pa√≠ses no se pueden utilizar para confeccionar los Scoring, como la informaci√≥n sobre sexo, estado civil o raza, por ejemplo, ya que se considera que pueden ser discriminatorias.

**Segunda etapa (Dise√±o del sistema de puntuaci√≥n):** Se emplean t√©cnicas estad√≠sticas como la regresi√≥n o las redes neuronales. La puntuaci√≥n se crea para clasificar a los individuos en diferentes grupos seg√∫n la probabilidad de pago de los pr√©stamos. La asignaci√≥n de puntos se realiza tras un an√°lisis detallado de operaciones similares para evaluar las caracter√≠sticas del riesgo. (Oriol, 2014).

El total de puntos que se asignan al cliente informan de la probabilidad de que el pr√©stamo tenga problemas, es decir, que no se retorne.  De esta manera, las entidades financieras establecen una clasificaci√≥n que suele desglosarse en muy bueno o bueno, regular o malo. Si un cliente se asigna a la categor√≠a "malo", es probable que se desestime su solicitud; mientras que si se asigna a la categor√≠a "regular", se pueden requerir m√°s garant√≠as y se podr√≠an ajustar las condiciones del pr√©stamo.
## <a name="_toc151738703"></a>2.2 ALFA Colombia
En ALFA Colombia, se disponen de herramientas de calificaci√≥n que facilitan la identificaci√≥n de la calidad crediticia de sus clientes mediante una valoraci√≥n y su relaci√≥n con las denominadas probabilidades de incumplimiento ("PD"). Para analizar la variaci√≥n de estas probabilidades, se cuenta con herramientas de seguimiento y bases de datos hist√≥ricas que recopilan la informaci√≥n necesaria. Esto permite la generaci√≥n de modelos de calificaci√≥n que se agrupan en sistemas de Scoring y Rating (ALFA, 2021)
### <a name="_toc151738704"></a>2.2.1 Rating
El rating, a diferencia de los scorings (que califican operaciones), es una herramienta enfocada a la calificaci√≥n de clientes: empresas, corporaciones, Pymes, administraciones p√∫blicas, etc.
### <a name="_toc151738705"></a>2.2.2 Scoring
El scoring es un modelo de decisi√≥n que facilita la concesi√≥n y gesti√≥n de cr√©ditos minoristas, tales como consumo, hipotecas y tarjetas de cr√©dito para particulares. En ALFA, existen dos tipos de scoring seg√∫n la informaci√≥n utilizada y su prop√≥sito:

Scoring reactivo: Eval√∫a el riesgo de una operaci√≥n solicitada por un individuo mediante variables relacionadas con el producto solicitado y datos socioecon√≥micos disponibles en el momento de la solicitud.

Scoring de comportamiento o proactivo: Asigna una puntuaci√≥n a nivel de cliente utilizando variables que consideran el comportamiento general del individuo con la entidad y su historial de pago en productos contratados. Su prop√≥sito es hacer un seguimiento de la calidad crediticia del cliente, utilizado para preconceder nuevas operaciones y gestionar el riesgo continuo de la entidad.

Al analizar la participaci√≥n de cada tipo de modelo en el c√°lculo de las Probabilidades de Incumplimiento (PD) de la cartera activa, se observa que el Scoring de Comportamiento o Proactivo tiene un peso del 84.4% sobre el total de la cartera en ALFA Colombia.

![](005.png)

**Tabla 1** Distribuci√≥n de la cartera en los diferentes modelos del banco.



![](006.png)![](007.png)Es por esto que se decide trabajar en un modelo de scoring de comportamiento, dada su importancia para el banco y la identificaci√≥n de deficiencias significativas en este √°mbito. Sin embargo, considerando que este segmento de clientes es amplio e incluye a todos los clientes particulares y personas naturales con negocio pertenecientes a la entidad, se opta por enfocarse espec√≠ficamente en el segmento de clientes que domicilian n√≥mina o pensi√≥n en el banco (ver Ilustraci√≥n 3).

El segmento en cuesti√≥n adquiere una gran importancia para el banco por dos motivos fundamentales. En primer lugar, es el segmento que presenta la mayor exposici√≥n de capital, lo que implica que su desempe√±o financiero y los riesgos asociados tienen un impacto significativo en la salud general de la instituci√≥n. En segundo lugar, este segmento se encuentra dentro de la estrategia a corto plazo del banco en t√©rminos de crecimiento. En consecuencia, se busca continuar expandiendo y fortaleciendo su presencia en dicho segmento, aline√°ndose con los objetivos y directrices establecidos por la organizaci√≥n.
## <a name="_toc151738706"></a>2.3 Modelo actual
El modelo actual de ALFA Scoring fue desarrollado por la consultora AIS en 2014, utilizando informaci√≥n hist√≥rica del comportamiento de los clientes en el banco entre los a√±os 2010 y 2012. Este modelo fue implementado en producci√≥n en 2015 y se divide en tres segmentos: clientes con √∫nicamente productos de pasivo (cuentas de ahorro, cuentas corrientes, fondos de inversi√≥n o CDTs), clientes con productos del activo que domicilian la n√≥mina o pensi√≥n con el banco (vinculados), y clientes del activo que no domicilian n√≥mina ni pensi√≥n con el banco (no vinculados).

El modelo actual est√° compuesto por tres regresiones log√≠sticas independientes, y la ponderaci√≥n por bloque informacional y su composici√≥n se puede observar en la ilustraci√≥n 4.

![](008.png)

**Ilustraci√≥n 4:** Distribuci√≥n y pesos del modelo actual
### <a name="_toc151738707"></a>2.3.1 Desempe√±o del modelo actual
Actualmente, el modelo de score comportamental presenta el siguiente desempe√±o en t√©rminos de Gini para los √∫ltimos meses evaluados, seg√∫n se muestra en la Tabla 2.

![](009.png)

**Tabla 2** Desempe√±o de los modelos actuales de Scoring.

Adem√°s, como se mencion√≥, este modelo se utiliza para generar campa√±as de preaprobado. Para esto, la calificaci√≥n del score se asigna a grupos de riesgo del 1 al 6 para los segmentos de activo y del 1 al 10 para el segmento pasivo, siendo los primeros grupos los de menor riesgo. En la Tabla 3, se puede observar c√≥mo se califican los clientes en los diferentes grupos durante un per√≠odo y qui√©nes ser√≠an los clientes ofertables de acuerdo a las pol√≠ticas de riesgo definidas por el banco.

![](010.png)

**Tabla 3** Grupo de riesgo de los modelos actuales de Scoring

Considerando lo expuesto, se observa que el 53% de los clientes est√°n siendo categorizados con una alta probabilidad de incumplimiento, mientras que la tasa de morosidad en entidades financieras reales es aproximadamente del 5%  (Experian, 2022) . Esto tiene un impacto directo en dos de los objetivos mencionados previamente: en primer lugar, en el crecimiento de la base de clientes, ya que existen muchos clientes potenciales que no est√°n siendo adecuadamente evaluados por el modelo; en segundo lugar, en la correcta aplicaci√≥n de datos y tecnolog√≠a, aspectos que se encuentran ausentes en el modelo actual.
# <a name="_toc428793021"></a><a name="_toc151738708"></a>3. Trabajos relacionados
La predicci√≥n de riesgo crediticio y la b√∫squeda de las mejores estrategias para cumplir con esta tarea han sido ampliamente estudiadas a lo largo de los a√±os, debido a la importancia que tienen tanto para las entidades financieras como para el sostenimiento y buen funcionamiento del mercado burs√°til en general. En este contexto, las instituciones financieras tradicionales suelen utilizar principalmente la regresi√≥n log√≠stica como metodolog√≠a de desarrollo. Esta t√©cnica utiliza una gran cantidad de datos hist√≥ricos para describir el nivel de ingresos del usuario, la capacidad de pago, el estado crediticio y otros indicadores. Luego, se dividen estos indicadores en varios niveles, generando as√≠ una tarjeta de puntuaci√≥n de riesgo (scorecard) (Jian, Haibin, Zhijun, & Lei, 2021).

Con el desarrollo de las finanzas por Internet, la aplicaci√≥n de m√©todos de aprendizaje autom√°tico (Nedellec et al. 1994; Boz et al. 2018; Shukla y Nanda 2019), por ejemplo, √Årbol de decisi√≥n (Kruppa et al. 2013), Red neuronal (Luo, Wu y Wu 2016), Montecarlo (Andrade y Sics√∫ 2008) y Extreme Gradient Boosting (XGBoost) (Liu, Huang y Xie 2019; Qiu 2019), en la predicci√≥n del riesgo de cr√©dito financiero comienza a florecer. Estos m√©todos tienen sus propias ventajas y desventajas (Zhang et al. 2007; Tran, Duong y Ho 2016; Wang et al. 2017; Li Y. 2019b; Hindist√°n et al. 2019; Wang et al. 2019a). Sin embargo, la aplicaci√≥n de an√°lisis de redes sociales (SNA) o el impacto ecol√≥gico de las diferentes metodolog√≠as son temas que no se han desarrollo a profundidad en la literatura y que solo cuentan con algunos pocos estudios.
## <a name="_toc151738709"></a>3.1 An√°lisis de redes sociales para la predicci√≥n de riesgo 
El an√°lisis de redes sociales en el contexto de las instituciones financieras ha sido objeto de atenci√≥n principalmente en lo que respecta a la evaluaci√≥n del contagio del riesgo entre dichas instituciones. Esto se evidencia en trabajos como el desarrollado por Bhattacharya, Inekwe y Valenzuela en 2020 o el desarrollado por Bundi en 2016. No obstante, estos estudios no se han llevado a cabo a nivel minorista debido a la complejidad que puede generar la granularidad de las interacciones. Es importante destacar que solo en la √∫ltima d√©cada se ha logrado adentrarse en detalle en esta granularidad.

Un ejemplo de esto es el trabajo desarrollado por √ìskarsd√≥ttir y Bravo en 2022 en el cual se aplica el an√°lisis de redes sociales (SNA) para predecir la probabilidad de incumplimiento en clientes con pr√©stamos agr√≠colas. Esto era particularmente relevante dada la sospecha de la existencia de una correlaci√≥n entre las tasas de impago entre los prestatarios expuestos a riesgos estructurales similares. Los hallazgos del estudio corroboran que la inclusi√≥n de informaci√≥n de red centralizada en el modelo conduce a importantes ganancias predictivas. Adem√°s, las ganancias aumentan cuando se incorpora informaci√≥n m√°s compleja, como las variables de PageRank de m√∫ltiples capas (√ìskarsd√≥ttir & Bravo, 2021).

En el contexto del problema que estamos abordando, que se refiere a las relaciones entre clientes individuales de pr√©stamos minoristas, es de gran importancia comprender los conceptos de redes dirigidas y no dirigidas. En las redes no dirigidas, dos nodos est√°n conectados o no lo est√°n, y es imposible que uno est√© conectado al segundo sin que el segundo est√© conectado al primero (Rishehchi Fayyaz, R. Rasouli, & Amiri, 2021). Este concepto suele ser v√°lido en el contexto social, como en relaciones de amistad o conocidos. Sin embargo, existen otros tipos de redes en las que un nodo puede estar conectado a un segundo nodo independientemente de si el segundo nodo est√° conectado al primero (Jackson, 2010), Debido a la naturaleza direccional de las transacciones monetarias, en el contexto de esta investigaci√≥n se consideran grafos como redes dirigidas.
## <a name="_toc151738710"></a>3.2 Eficiencia energ√©tica entre metodolog√≠as de predicci√≥n
La utilizaci√≥n de herramientas de predicci√≥n basadas en el aprendizaje autom√°tico, destinadas a lograr la precisi√≥n predictiva a trav√©s de propiedades b√°sicas de entrenamiento conocidas, es una pr√°ctica omnipresente en la industria (Omar Y, Paul D, Sami, George, & Kamal, 2015).Sin embargo, muchos de estos modelos no param√©tricos basados en aprendizaje autom√°tico requieren un alto costo computacional para encontrar los √≥ptimos globales. La complejidad de estos modelos aumenta exponencialmente con el n√∫mero de iteraciones en las tareas de aprendizaje que implican grandes conjuntos de datos. Esto, a su vez, conduce a un aumento significativo de la complejidad computacional (Dandres, Schmidt, Luccioni, & Lacoste, 2019). 

Esta expansi√≥n del aprendizaje autom√°tico (AI)  lleva de igual manera a que cada vez el consumo de recursos energ√©ticos y la cantidad de emisiones de carbono aumenten de igual manera. En 2015 se estimaba que un 2% del total de emisiones eran generadas por la industria de tecnolog√≠a y comunicaciones (Omar Y, Paul D, Sami, George, & Kamal, 2015). De igual manera estudios recientes tambi√©n han evaluado el impacto clim√°tico de la AI, centr√°ndose principalmente en el costo ambiental del entrenamiento de modelos a gran escala que est√°n conectados a redes alimentadas por combustibles f√≥siles que al utilizar m√∫ltiples GPUs durante largos per√≠odos de tiempo, implican un consumo de energ√≠a cada vez mayor (Dandres, Schmidt, Luccioni, & Lacoste, 2019). 

En cuanto a la b√∫squeda de hiperpar√°metros, se ha demostrado tanto de manera emp√≠rica como te√≥rica que la b√∫squeda aleatoria de hiperpar√°metros es m√°s eficiente que la b√∫squeda en cuadr√≠cula para la optimizaci√≥n. Adem√°s, es importante considerar la ubicaci√≥n geogr√°fica del servidor, el tipo de unidad de procesamiento gr√°fico (GPU) utilizada y la duraci√≥n del entrenamiento, ya que estos factores tienen un impacto directo en la cantidad aproximada de CO2 que se produce durante el proceso de entrenamiento del modelo (Eggleston, Buendia, Miwa, Ngara, & Tanabe, 2006). En este sentido, es alentador destacar que compa√±√≠as como Amazon Web Services (AWS) toman medidas para que sus centros de datos ya funcionan con fuentes de energ√≠a renovable (Amazon Web Services, 2023).

Es por todo esto que, se vuelve relevante que durante el proceso de concepci√≥n y desarrollo de c√≥digos destinados a la predicci√≥n, se analice detenidamente el posible impacto energ√©tico de las diversas soluciones propuestas (Abdulsalam, Lakomski, Qijun, Tongdan, & Zong, 2015). Por tanto, adem√°s de su objetivo principal, de desarrollar un nuevo modelo de Scoring para los clientes vinculados, se quiere calcular el impacto energ√©tico asociado a dichas metodolog√≠as. Asimismo, se busca analizar el impacto energ√©tico de las estrategias de b√∫squeda de hiperpar√°metros utilizadas durante el entrenamiento de los modelos de predicci√≥n.
# ` `<a name="_toc151738711"></a>4 Comprensi√≥n de los datos
## <a name="_toc151738712"></a>4.1 Descripci√≥n de los datos
Para este proyecto, se emplear√°n dos fuentes de informaci√≥n principales. La primera consiste en una base de datos construida por el √°rea de analytics, que incorpora aproximadamente 700 variables internas y externas a nivel de cliente. Estas variables se consideran predictivas de riesgo tanto desde una perspectiva estad√≠stica[^1] o por criterio experto. Adem√°s de las variables explicativas, la base tambi√©n cuenta con las variables objetivo que son utilizadas en diferentes modelos del √°rea. 

La segunda fuente de informaci√≥n es la base de datos transaccional, que registra los movimientos financieros de los clientes a nivel de transacci√≥n. En esta base, se encuentran registrados datos como la fecha, el monto, la identificaci√≥n del origen y la identificaci√≥n del destino de las transacciones realizadas.



![](011.png)Como se mencion√≥ anteriormente, el √°rea trabaja con diferentes targets seg√∫n el enfoque del modelo. En este caso, y por decisi√≥n del √°rea usuaria del modelo, se va a trabajar con un target de incumplimiento de 90 d√≠as con vista a 12 meses, lo cual se puede entender mediante la siguiente gr√°fica.

Debido a la decisi√≥n de trabajar exclusivamente en el segmento vinculado, que, como mencionamos anteriormente, es el segmento m√°s grande en cuota y cantidad de clientes, se opta por trabajar con una muestra de los clientes en cada trimestre. Para ello, se lleva a cabo una muestra estratificada simple con respecto a la fecha y al incumplimiento del cliente. De esta manera, la cantidad de clientes y la proporci√≥n de incumplimiento del proyecto ser√≠an las siguientes:

![](012.png)

**Tabla 4.** Selecci√≥n de la muestra para generaci√≥n del modelo
## <a name="_toc151738713"></a>4.2 Estructura de los datos
### <a name="_toc151738714"></a>4.2.1 Base variables explicativas
La primera base del proyecto es una muestra de 677.378 registros del segmento vinculado que se extrae consolidado de variables que maneja el banco, la informaci√≥n ac√° contenida se divide en bloques informacionales que dependen del origen de la misma y est√° dividida de la siguiente manera:

- **Endeudamiento:** Tabla informacional mensual que contiene el detalle de obligaciones crediticias en balance en el banco a cierre de mes, as√≠ como detalles de saldos y d√≠as de atraso.
- **Pasivo:** Informaci√≥n de tipo mensual asociada a los productos del pasivo del cliente, como cuentas corrientes, de ahorro, fondos de inversi√≥n y CDT.
- **N√≥mina / Pensi√≥n:** Informaci√≥n relacionada a las cuentas de n√≥mina y pensi√≥n del cliente, as√≠ como los valores aportados los √∫ltimos tres meses.
- **Obligaciones Canceladas:** identifica todas las posibles obligaciones activas y canceladas que ha tenido un cliente de forma hist√≥rica, incluyendo la totalidad de productos (seguros, garant√≠as, cr√©dito, cuentas de ahorro, etc). Cuenta adem√°s con informaci√≥n de perfil como edad, estrato y sucursal asociada a sus productos.
- **Transaccionalidad:** Informaci√≥n que contiene el detalle de interacciones del cliente y permite identificar tanto informaci√≥n asociada a transferencias, como pagos, compras, consultas entre otros.
- **Bureau de cr√©dito (Qualities):** Informaci√≥n de los cr√©ditos activos y cancelados del Sistema Financiero Colombiano, as√≠ como alguna informaci√≥n relacionada al Sector Real y Telecomunicaciones.
### <a name="_toc151738715"></a>4.2.2 Base transaccional
Tabla con informaci√≥n hist√≥rica que detalla las interacciones del cliente a trav√©s de varios canales (web, m√≥vil, oficina, etc.). En ella se puede identificar tanto el usuario originador de la transacci√≥n como el monto y el destinatario de la misma. La tabla est√° organizada a nivel de transacci√≥n por d√≠a e incluye las siguientes columnas

|**Campo**|**Descripci√≥n**|
| :- | :- |
|transaction\_payment\_method\_type|<p>C√≥digo interno de transaccionalidad para identificar la forma en que un cliente realiza un pago en la operaci√≥n. Ejemplos incluyen:</p><p>Efectivo</p><p>Cheque</p><p>Otros</p>|
|transaction\_amount|<p>Cuant√≠a reflejada en la transacci√≥n ejecutada derivada de una operaci√≥n bancaria entre el cliente y la entidad. Puede expresarse en distintas divisas, como:</p><p>Divisa de Liquidaci√≥n: Divisa sobre la que se ha formalizado el contrato del cliente</p><p>Divisa Origen: Pa√≠s o geograf√≠a distinta al pa√≠s del contrato del cliente</p>|
|transaction\_subchannel\_id|C√≥digo interno de transaccionalidad que identifica el subcanal a trav√©s del cual se realiza una transacci√≥n.|
|transaction\_operation\_type|<p>C√≥digo interno de transaccionalidad que identifica la agrupaci√≥n funcional de la tipolog√≠a de operativa que es posible realizar y registrar. Ejemplos incluyen:</p><p>Consulta</p><p>Contrataci√≥n</p><p>Operaciones autom√°ticas</p><p>Operaciones internas de la entidad</p><p>Otros</p>|
|ori\_customer\_id|C√≥digo identificativo un√≠voco del cliente ordenante de una operaci√≥n.|
|ben\_customer\_id|C√≥digo identificativo un√≠voco del cliente beneficiario de una operaci√≥n.|
|payment\_method\_type|<p>Marca utilizada para identificar la forma en que un cliente realiza un pago a la entidad. Ejemplos incluyen:</p><p>Efectivo</p><p>Tarjeta</p><p>Otros</p>|
|transaction\_channel\_id|C√≥digo interno de transaccionalidad que identifica el canal a trav√©s del cual se realiza una transacci√≥n.|
|operation\_date|Fecha en la que se realiza la operativa bancaria a la que va ligada la operaci√≥n o movimiento. Puede no coincidir con la fecha en que se hace efectiva (fecha valor). Ejemplo: En una transferencia, la fecha de ejecuci√≥n corresponder√° al momento en que se ordena, aunque se har√° efectiva y es posible que llegue a la cuenta destino horas/d√≠as m√°s tarde.|

**Tabla 5** Descripci√≥n de variables tabla transaccional** 
# <a name="_toc428793025"></a><a name="_toc151738716"></a>5.  An√°lisis de redes 
## <a name="_toc428793027"></a><a name="_toc151738717"></a>5.1 Preparaci√≥n de data
Dado que nuestro proyecto se enfoca en analizar las relaciones monetarias entre clientes del banco, se llevan a cabo varios tratamientos antes de generar el grafo:

- Se excluyen clientes que no pertenecen a la muestra de desarrollo.
- Se realiza un filtro para incluir √∫nicamente los clientes y transacciones de los a√±os de desarrollo (2018,2019, 2020, 2021)  
- Se excluyen transacciones que no tienen car√°cter monetario, como consultas, alertas, etc.
- Se realiza una agregaci√≥n de las transacciones a nivel mensual:

![](013.png)

**Tabla 6** Campos de transacci√≥n luego de transformaci√≥n.

<a name="_toc428793028"></a>Despu√©s de obtener la base tratada y agrupada a nivel mensual, se inicia la siguiente fase del an√°lisis, que consiste en la construcci√≥n del grafo.
## <a name="_toc151738718"></a>5.2 Construcci√≥n de grafo
La construcci√≥n del grafo se llev√≥ a cabo en varias etapas para explorar diferentes temporalidades y considerar tanto el peso como la cantidad de transacciones entre clientes. Se generaron un total de 6 grafos para cada per√≠odo de observaci√≥n. A continuaci√≥n, se describen los detalles de cada grafo.

Considerando lo mencionado anteriormente, se construyeron un total de 6 grafos de iteraciones para cada per√≠odo de observaci√≥n de la siguiente manera:** 

**Grafo 1**: iteraciones entre clientes en el √∫ltimo a√±o donde el peso de las iteraciones sea el monto de las transacciones (si estamos en el periodo marzo del 2020 se toman las iteraciones desde abril del 2019 hasta marzo de 2020).

**Grafo** **2**: iteraciones entre clientes en el √∫ltimo a√±o donde el peso de las iteraciones sea la cantidad de transacciones (si estamos en el periodo marzo del 2020 se toman las iteraciones desde abril del 2019 hasta marzo de 2020).

**Grafo 3**: iteraciones entre clientes en los √∫ltimos seis meses donde el peso de las iteraciones sea el monto de las transacciones (si estamos en el periodo marzo del 2020 se toman las iteraciones desde octubre del 2019 hasta marzo de 2020).

**Grafo 4**: iteraciones entre clientes en los √∫ltimos seis meses donde el peso de las iteraciones sea la cantidad de transacciones (si estamos en el periodo marzo del 2020 se toman las iteraciones desde octubre del 2019 hasta marzo de 2020).

**Grafo 5**: iteraciones entre clientes en los √∫ltimos tres meses donde el peso de las iteraciones sea el monto de las transacciones (si estamos en el periodo marzo del 2020 se toman las iteraciones desde enero del 2020 hasta marzo de 2020).

**Grafo 6:** iteraciones entre clientes en los √∫ltimos tres meses donde el peso de las iteraciones sea la cantidad de transacciones (si estamos en el periodo marzo del 2020 se toman las iteraciones desde enero del 2020 hasta marzo de 2020).

Podemos observar los grafos generados para el periodo de observaci√≥n de junio del 2022 en cada una de las seis condiciones:

![](014.png)![](015.png)

**Ilustraci√≥n 6:** Grafos vistos a un a√±o el de la derecha con peso por monto de transacci√≥n y el de la izquierda por cantidad

![](016.png)![](017.png)

**Ilustraci√≥n 7:** Grafos vistos a seis meses el de la derecha con peso por monto de transacci√≥n y el de la izquierda por cantidad

![](018.png) ![](019.png)

**Ilustraci√≥n 8:** Grafos vistos a tres meses el de la derecha con peso por monto de transacci√≥n y el de la izquierda por cantidad

## <a name="_toc151738719"></a>5.3 Selecci√≥n de variables a incluir en modelo
En la teor√≠a del an√°lisis de redes sociales una de las principales aplicaciones es la identificaci√≥n de los actores ‚Äúm√°s importantes‚Äù en la red y para esto existen diversas medidas que describen y eval√∫an los la ubicaci√≥n de los actores dentro de la red. Para esto se eval√∫an distintas definiciones de importancia o prominencia, como el grado, la cercan√≠a, la intermediaci√≥n y el estatus de los actores. Estas definiciones generan √≠ndices que cuantifican la importancia de los actores individual y grupalmente en la red (Wasserman & Faust, 1994).

En el caso de este proyecto las medidas que se calcularon sobre los grafos generados son las siguientes:

- **PageRank**: Es un algoritmo de clasificaci√≥n que se basa en la idea de que un nodo es importante si es enlazado por otros nodos importantes. El algoritmo asigna una puntuaci√≥n de importancia a cada nodo, lo que permite identificar los nodos m√°s relevantes dentro de la red. 
- **Centralidad por Grado (Degree Centrality):** La centralidad por grado se refiere a la cantidad de conexiones que tiene un nodo en la red. Cuantas m√°s conexiones tenga un nodo, mayor ser√° su centralidad por grado. 
- **Centralidad de Eigenvector (Eigenvector Centrality):** La centralidad de eigenvector eval√∫a la importancia de un nodo en funci√≥n de la importancia de sus vecinos. Un nodo tiene una alta centralidad de eigenvector si est√° conectado a otros nodos importantes en la red. 
- **Grado:** El grado de un nodo en una red social se refiere al n√∫mero de conexiones que tiene ese nodo con otros nodos. Un nodo con un alto grado tiene muchas conexiones, mientras que un nodo con un bajo grado tiene pocas conexiones.

Tomando esto en cuenta en total por medio del an√°lisis de redes se obtienen un total de veinticuatro m√©tricas que se incluir√°n en dataset de informaci√≥n por cada periodo de observaci√≥n.
# <a name="_toc151738720"></a>6.  Preparaci√≥n de datos 
## <a name="_toc151738721"></a>6.1 Selecci√≥n de los datos
Una vez se termina la ejecuci√≥n variables derivadas del grafo esta informaci√≥n se une a la base de variables explicativas, para al final tener un set de datos de 781 variables, distribuidas de la siguiente forma:

![](020.png)

Tabla 7: Total de variables por categor√≠a
## <a name="_toc151738722"></a>6.3 Estructuraci√≥n de los datos
La estructuraci√≥n y limpieza de los datos se lleva a cabo en dos etapas distintas. En la primera fase, se realiza un an√°lisis bivariante de los datos en relaci√≥n con el objetivo deseado (target) con el prop√≥sito de observar el comportamiento de cada variable en funci√≥n del objetivo y, en consecuencia, eliminar aquellas que aporten poca informaci√≥n predictiva. Adem√°s, en esta fase, las variables se transforman mediante la metodolog√≠a de "Weight of Evidence" (woe) para mejorar su capacidad predictiva.

En la segunda fase, se examina la correlaci√≥n entre las variables y, en particular, se identifican aquellas que presentan una alta correlaci√≥n. Con el objetivo de evitar problemas de multicolinealidad, se procede a eliminar una de las variables altamente correlacionadas que tenga un menor valor de Information Value (IV).
### <a name="_toc151738723"></a>6.3.1 An√°lisis Bivariante
La primera parte de este proceso es la trasformaci√≥n de las variables a woe, esta metodolog√≠a se utiliza para transformar una variable independiente continua en grupos o contenedores, bas√°ndose en la similitud de la distribuci√≥n de la variable dependiente, es decir, el n√∫mero de eventos y no eventos (Deepanshu, 2023).

El WOE ofrece varios beneficios para mejorar modelos predictivos:

- Permite tratar valores at√≠picos al agruparlos en clases espec√≠ficas.
- Maneja los valores faltantes al asignarles valores distintos.
- Elimina la necesidad de crear variables ficticias para variables categ√≥ricas.
- Facilita la construcci√≥n de relaciones lineales con las probabilidades logar√≠tmicas, algo m√°s complejo con otros m√©todos de transformaci√≥n.

De esta manera, las variables se agrupan en distintos grupos, que pueden variar desde 2 hasta 13, dependiendo del comportamiento espec√≠fico de cada variable. A continuaci√≥n, se presenta un ejemplo para ilustrar el proceso.

![](021.png)

**Ilustraci√≥n 9:** Divisi√≥n de variables en tramos por metodolog√≠a WoE

![](022.png)

**Ilustraci√≥n 10:** Comportamiento de la variable por tramos en el tiempo

En la primera ilustraci√≥n, se presentan los tramos en los que se dividi√≥ cada variable, junto con su valor WOE y el IV (Valor de Informaci√≥n) correspondiente para cada tramo. Por otro lado, en la segunda imagen, se muestra el comportamiento de cada grupo a lo largo del tiempo.

Adem√°s, en el Anexo 2 se proporciona informaci√≥n detallada para cada variable, incluyendo la cantidad de tramos en que se dividi√≥, su IV y el Gini individual de la variable en comparaci√≥n con el target. En esta secci√≥n, presentaremos √∫nicamente en los resultados de las variables con el valor de informaci√≥n m√°s alto.

![](023.png)

**Ilustraci√≥n 11:** Resultados del an√°lisis bivariante para variable 240 del bloque Nomina

![](024.png)

**Ilustraci√≥n 13:** Resultados del an√°lisis bivariante para variable 12 del bloque Bureau

En esta parte del proceso se eliminan las variables que tengan un information value menor al 2% como por ejemplo la variable 10 del bloque bureau.

![](025.png)

**Ilustraci√≥n 14:** Resultados del an√°lisis bivariante para variable 10 del bloque Bureau

Una vez realizado este proceso de depurado la cantidad de variables finales por segmento son:

![](026.png)

**Tabla 8:** Limpieza de variables en an√°lisis Bivariante
### <a name="_toc151738724"></a>6.3.2 An√°lisis de correlaciones
En la fase de depuraci√≥n de las bases de datos, se realiza una evaluaci√≥n exhaustiva de la correlaci√≥n entre las variables, tanto en relaci√≥n a ellas mismas como en relaci√≥n al objetivo (target) del modelo. Durante este proceso, se toma la decisi√≥n de eliminar aquellas variables que presenten una correlaci√≥n superior al 60% con el objetivo o una correlaci√≥n superior al 80% con otras variables en el conjunto. En esta etapa, hemos eliminado un total de 394 variables que cumplen con estos criterios de alta correlaci√≥n, optimizando as√≠ la calidad del conjunto de datos.

Para obtener un an√°lisis detallado de las correlaciones entre cada par de variables, se proporciona el Anexo 3, donde se presenta la informaci√≥n detallada sobre los valores de correlaci√≥n entre las variables.
# <a name="_toc151738725"></a>7. Modelado
## <a name="_toc151738726"></a>7.1 Selecci√≥n de t√©cnicas de Modelado 
Los an√°lisis predictivos desempe√±an un papel esencial al permitir realizar conjeturas sobre eventos futuros. Estas conjeturas se fundamentan en el estudio de acontecimientos pasados, la evaluaci√≥n de la situaci√≥n actual y la proyecci√≥n hacia d√≥nde nos dirigimos. A trav√©s del an√°lisis de tendencias, patrones y relaciones en datos, tanto estructurados como no estructurados, esta metodolog√≠a proporciona una perspicacia valiosa que se puede utilizar para prever acontecimientos futuros y tomar medidas con el fin de lograr resultados espec√≠ficos.

En el contexto de este estudio, el objetivo principal es anticipar la probabilidad de que un cliente experimente ciertos eventos en los pr√≥ximos 12 meses. Para lograrlo, se han sometido a prueba diversas t√©cnicas estad√≠sticas que permiten inferir esta probabilidad. Estas t√©cnicas se basan en la informaci√≥n recopilada y extra√≠da durante el proceso de desarrollo.

En el dise√±o de este modelo, se han evaluado varias t√©cnicas de an√°lisis cuidadosamente seleccionadas, con un enfoque especial en su capacidad explicativa, una cualidad esencial para las entidades financieras. Entre las t√©cnicas empleadas en esta fase se encuentran:

- Regresi√≥n Log√≠stica
- Random Forest
- XGBoost

A continuaci√≥n, se presenta una breve descripci√≥n de la metodolog√≠a utilizada, junto con sus matices y particularidades.
### <a name="_toc151738727"></a>7.1.1 Random Forest:
Los Bosques Aleatorios, o Random Forest, constituyen una combinaci√≥n de √°rboles de decisi√≥n, que son clasificadores d√©biles. Esta t√©cnica representa una modificaci√≥n del Bagging, donde se trabaja con una colecci√≥n de √°rboles correlacionados y se promedian (Hastie, Friedman y Tibshirani, 2001). En este enfoque, cada √°rbol depende de los valores de un vector aleatorio de la muestra de manera independiente y con la misma distribuci√≥n en todo el bosque. Se observa que la generalizaci√≥n del error para los bosques converge a un l√≠mite a medida que el n√∫mero de √°rboles en el bosque aumenta.

El error de generalizaci√≥n de un bosque de √°rboles de clasificaci√≥n est√° influenciado por la fuerza de los √°rboles individuales en el bosque y la correlaci√≥n entre ellos. La utilizaci√≥n de una selecci√≥n aleatoria de caracter√≠sticas para dividir cada nodo contribuye a tasas de error que se comparan favorablemente con el algoritmo AdaBoost (Freund y Schapire, 1996), pero muestra una mayor robustez frente al ruido, lo que lo convierte en un clasificador m√°s fuerte.
### <a name="_toc151738728"></a>7.1.2 XGBoost (Extreme Gradient Boosting)
XGBoost es un m√©todo de c√≥digo abierto ampliamente utilizado en retos y proyectos de miner√≠a de datos, como las competiciones de machine learning en plataformas como Kaggle. Este algoritmo implementa el boosting, realizando ùêæ iteraciones en las cuales se a√±ade un nuevo √°rbol de decisi√≥n en cada una. El prop√≥sito de cada nuevo √°rbol es corregir los errores cometidos en las iteraciones anteriores, con el objetivo de minimizar el error acumulado por los √°rboles previos.

Los √°rboles en XGBoost siguen una estructura que, en cada nodo interno, bifurca una variable seg√∫n la condici√≥n ùë£ùëéùëüùëñùëéùëèùëôùëí < ùë¢ùëöùëèùëüùëéùëô. Este proceso clasifica las variables de entrada de manera repetitiva hasta alcanzar el nodo hoja correspondiente. La selecci√≥n de la variable y sus umbrales en cada nodo se realiza de manera que minimice la funci√≥n objetivo. Una vez en el nodo hoja, se obtiene un valor para la variable en cuesti√≥n, y el resultado final es el promedio ponderado, seg√∫n los pesos de cada √°rbol del ensamble (Ilustraci√≥n 15).

![](027.png)

**Ilustraci√≥n 15:** Ejemplo sencillo de XGBoost. 
### <a name="_toc151738729"></a>7.1.3 Regresi√≥n Log√≠stica
La regresi√≥n log√≠stica es una herramienta estad√≠stica utilizada para predecir situaciones en las que se tiene una variable dependiente que es dicot√≥mica (por ejemplo, presente/ausente representados como 1/0) y un conjunto de variables predictoras, que pueden ser cuantitativas o categ√≥ricas (las √∫ltimas deben convertirse en variables "dummy").

Esta metodolog√≠a tiene dos objetivos principales:

- Predecir la probabilidad de que ocurra un evento espec√≠fico, como estar desempleado (1) o no (0), ser pobre (1) o no (0), o graduarse como soci√≥logo (1) o no (0).
- Determinar qu√© variables influyen m√°s en el aumento o disminuci√≥n de la probabilidad de que ocurra el evento en cuesti√≥n.

Para lograr esto, se basa en las caracter√≠sticas de los individuos que han experimentado o no el evento en cuesti√≥n. Por ejemplo, si estamos analizando el desempleo, la regresi√≥n log√≠stica considerar√° las caracter√≠sticas (edad, sexo, educaci√≥n, posici√≥n en el hogar, origen migratorio, etc.) de las personas que est√°n desempleadas (1) y las que no lo est√°n (0). A partir de estas caracter√≠sticas, se calcula una probabilidad para cada individuo, independientemente de su estado actual. Por ejemplo, un joven no jefe de hogar con poca educaci√≥n, sexo masculino y origen migrante podr√≠a tener una alta probabilidad de estar desempleado, aunque est√© trabajando actualmente, debido a la tasa de desempleo en ese grupo.

Adem√°s, la regresi√≥n log√≠stica analiza el impacto de cada variable independiente en el aumento o disminuci√≥n de la probabilidad del evento. Por ejemplo, la educaci√≥n tiende a reducir la probabilidad de desempleo, mientras que el g√©nero masculino puede aumentarla. El modelo estima los coeficientes de estos efectos (Chitarroni, 2022).
## <a name="_toc151738730"></a>7.2 Generaci√≥n de un plan de prueba
Como enfoque metodol√≥gico, se propone la utilizaci√≥n de dos conjuntos de datos distintos para cada t√©cnica de modelado abordada en el presente documento. Espec√≠ficamente, un conjunto de datos incorporar√° las variables de an√°lisis de redes, mientras que el otro conjunto las excluye por completo. A trav√©s de este enfoque bimodal, se busca una evaluaci√≥n exhaustiva de los resultados obtenidos en funci√≥n de la presencia o ausencia de estas variables derivadas del an√°lisis de redes sociales en el proceso de modelado.

Cabe destacar que, en consonancia con las directrices normativas regidas por ALFA, la m√©trica principal para evaluar los modelos concebidos es el coeficiente Gini. Dicha elecci√≥n se sustenta en su capacidad para medir la probabilidad de que dos elementos extra√≠dos al azar de una poblaci√≥n exhiban pertenencia a clases distintas. Esta caracter√≠stica lo posiciona como una herramienta especialmente apta para el abordaje de problemas de clasificaci√≥n. De manera crucial, el coeficiente Gini considera tanto los verdaderos como los falsos positivos y negativos, brindando as√≠ una visi√≥n hol√≠stica del rendimiento del modelo en cuesti√≥n.

La interpretaci√≥n del rango de esta m√©trica, que oscila entre 1 (denotando una clasificaci√≥n perfecta) y 0.5 (indicando una clasificaci√≥n al azar), facilita de sobremanera la comparaci√≥n entre diferentes modelos y, en √∫ltima instancia, la toma de decisiones informadas. Es oportuno mencionar que su eficacia se extiende a contextos en los que se presenta un desequilibrio entre las clases, lo que otorga relevancia en diversas aplicaciones financieras. Adem√°s, su idoneidad se hace evidente al poder aplicarse en variados algoritmos de clasificaci√≥n, abarcando desde √°rboles de decisi√≥n hasta bosques aleatorios y regresi√≥n log√≠stica, entre otros. 
## <a name="_toc151738731"></a>7.3 Construcci√≥n del modelo
Como se hizo menci√≥n previamente, se llevan a cabo dos ejercicios independientes para cada t√©cnica de modelado, lo que resulta en un total de seis ejercicios de modelado distintos. Cada uno de estos ejercicios, en funci√≥n de la t√©cnica de modelado empleada, sigue sus propios flujos de trabajo que se detallar√°n en lo que sigue. Es relevante destacar que, durante el proceso de calibraci√≥n para identificar el mejor modelo en todas las situaciones, se estableci√≥ como criterio que la diferencia entre el √≠ndice Gini obtenido en el conjunto de entrenamiento y el √≠ndice Gini logrado en el conjunto de prueba no excediera el 5%. Esta consideraci√≥n se adopt√≥ con el prop√≥sito de evitar que los modelos resultaran en una situaci√≥n de sobreestimaci√≥n.
### <a name="_toc151738732"></a>7.3.1 Regresi√≥n log√≠stica
A continuaci√≥n se presenta el esquema general del proceso que se sigui√≥ para la obtenci√≥n del mejor modelo utilizando regresi√≥n log√≠stica, para m√°s detallas sobre el mismo por favor consultar los anexos 5 y 6.

![](028.png)

**Ilustraci√≥n 16:** Flujo de proceso regresi√≥n log√≠stica
### <a name="_toc151738733"></a>7.3.2 Random Forest
A continuaci√≥n, se presenta el esquema general del proceso seguido para obtener el mejor modelo utilizando Random Forest. Es importante destacar que, atendiendo a la solicitud de ALFA con respecto a los modelos de aprendizaje autom√°tico (Random Forest y Xgboost), si bien las metodolog√≠as permiten obtener resultados en conjuntos de datos con un elevado n√∫mero de variables, las limitaciones de ingenier√≠a de los aplicativos utilizados para la interacci√≥n directa con el cliente requieren que los modelos se restrinjan a un m√°ximo de 40 variables. Conscientes de esta restricci√≥n, se llev√≥ a cabo un proceso de b√∫squeda recursiva de las mejores variables, considerando las m√°s relevantes identificadas durante la ejecuci√≥n con el conjunto de datos completo. Para obtener informaci√≥n detallada sobre el proceso, se recomienda consultar los anexos 7 y 8.

![](029.png)

**Ilustraci√≥n 17:** Flujo de proceso de Random Forest
### <a name="_toc151738734"></a>7.3.3 Xgboost
A continuaci√≥n se presenta el esquema general del proceso que se sigui√≥ para la obtenci√≥n del mejor modelo utilizando Xgboost en los cuales tambi√©n se aplic√≥ la restricci√≥n de variables, para m√°s detallas sobre el mismo por favor consultar los anexos 9 y 10.

![](030.png)

**Ilustraci√≥n 18:** Flujo de proceso Xgboost
## <a name="_toc151738735"></a>7.4 Evaluaci√≥n del modelo
Despu√©s de llevar a cabo la ejecuci√≥n y obtener los resultados m√°s destacados para cada metodolog√≠a, los resultados finales, los par√°metros que hemos obtenido y la distribuci√≥n de los tipos de variables en cada ejecuci√≥n se presentan a continuaci√≥n:

![](031.png)

**Tabla 9:** Resultados de ejecuci√≥n de modelos

La importancia de cada variable en los modelos, junto con los resultados consolidados de las ejecuciones, se detalla en el anexo 11.
## <a name="_toc151738736"></a>7.5 Evaluaci√≥n de los resultados
La metodolog√≠a que claramente genera mejores resultados en cuanto a predicci√≥n es XGBoost, por lo tanto, consideraremos √∫nicamente estos dos modelos para evaluar su desempe√±o en diversas caracter√≠sticas.
### <a name="_toc151738737"></a>7.5.1 Poder de predicci√≥n del modelo
El poder discriminante del modelo se ha medido con el Coeficiente de GINI. Este coeficiente mide el grado de concentraci√≥n de un atributo en una poblaci√≥n. En este caso estamos midiendo el grado de concentraci√≥n del scoring de los clientes malos en la cartera. Si este coeficiente toma valor cero, entonces el scoring de los clientes malos se distribuye uniformemente y no es posible detectar diferencias con el scoring de los clientes buenos.

Ante esta situaci√≥n, el scoring no distinguir√≠a entre buenos y malos. Gr√°ficamente, el coeficiente de GINI es el cociente entre 2 √°reas:

![](032.png)

**Ilustraci√≥n 19:** Gini

Adicionalmente se ha calculado el estad√≠stico de Kolmogorov-Smirnov (KS). Este estad√≠stico se define como la distancia m√°xima entre la funci√≥n de distribuci√≥n emp√≠rica de las clasificaciones de los registros morosos y la funci√≥n de distribuci√≥n emp√≠rica de los registros no morosos. El rango en el que se mueve este estad√≠stico es de 0 a 1. Dado que se desea que el modelo sea lo m√°s discriminante posible, contra m√°s cercano sea este valor a 1, el modelo ser√° m√°s discriminante.

|¬†|***Gini***|***KS***¬†||||
| :- | :-: | :-: | :-: | :- | :- |
|Metodolog√≠a|Training|Test|Training|Test|N¬∫ variables|
|XGB ‚Äì No Grafo|68,64%|64,92%|52,88%|49,52%|25|
|XGB ‚Äì Grafo|70,10%|66,84%|54,53%|51,57%|30|

**Tabla 10:** Resultados de modelos XgBoost

Adicionalmente, Podemos ver el comportamiento temporal del Gini en cada periodo temporal analizado donde vemos que los modelos son estables.

![](033.png)

Tabla 11: Comportamiento temporal del Gini con grafo

![](034.png)

Tabla 12: Comportamiento temporal del Gini sin grafo
### <a name="_toc151738738"></a>7.5.2 Resultados de eficiencia del modelo
Para hacer una correcta interpretaci√≥n del modelo y tener un conocimiento exhaustivo, es importante ver la distribuci√≥n de la morosidad por intervalo de probabilidad de default o de puntuaci√≥n. Por ello, se ha generado primero una tabla de eficiencia con la base de datos del entrenamiento y luego usando los intervalos ya obtenidos se ha creado otra tabla de eficiencia para la base de prueba. El objetivo de este an√°lisis es mostrar que el ratio entre malos y buenos es mon√≥tono. Los resultados se ven en el anexo 12.
### <a name="_toc151738739"></a>7.5.3 Estabilidad del modelo
Al estimar un modelo, se desea maximizar la m√©trica de discriminaci√≥n (GINI). Sin embargo, tambi√©n es importante obtener un modelo que sea estable. Por eso se han realizado los siguientes an√°lisis:

- El cambio de la distribuci√≥n de la puntuaci√≥n a lo largo del tiempo: No se espera observar cambios dr√°sticos de T a T+1. Por ello, el modelo elegido no deber√≠a mostrar diferencias significativas en la distribuci√≥n de la puntuaci√≥n a lo largo del tiempo. 
- El cambio de la distribuci√≥n de las variables que forman parte del modelo a lo largo del tiempo. La estabilidad de la puntuaci√≥n final depende de la estabilidad de las variables de entrada. Por eso, adem√°s de la distribuci√≥n de la puntuaci√≥n, tambi√©n se han analizado las variables de input.

![](035.png)

**Ilustraci√≥n 20** Distribuci√≥n del score en cada periodo temporal en modelo con grafo

![](036.png)

**Ilustraci√≥n 21** Distribuci√≥n del score en cada periodo temporal en modelo con grafo

Los resultados complementarios se presentan en el anexo 13.
### <a name="_toc151738740"></a>7.5.4 Resultados de desempe√±o versus modelo actual 
Para evaluar el impacto potencial de la implementaci√≥n del nuevo modelo, se procedi√≥ a realizar un an√°lisis retrospectivo utilizando los mismos clientes de la muestra de desarrollo. Se accedi√≥ al historial de resultados del modelo actual y se calcul√≥ el √≠ndice Gini, empleando el mismo target utilizado durante el desarrollo del presente proyecto, que se define como aquellos clientes que presentan mora mayor a 90 d√≠as con una perspectiva de 12 meses.

Los resultados de esta comparaci√≥n se detallan en las Ilustraciones 22 y 23, tanto para el modelo que incorpora variables de grafo como para aquel en el que estas variables no est√°n presentes.

![](037.png)

**Ilustraci√≥n 22.** Desempe√±o modelo actual versus XGB sin grafo

![](038.png)

**Ilustraci√≥n 23** Desempe√±o modelo actual versus XGB sin grafo 

Los resultados derivados de la comparaci√≥n entre los nuevos modelos y el modelo actual revelan avances significativos, destac√°ndose mejoras sustanciales en diversas cohortes. Por ejemplo, en la cohorte de marzo de 2019, el √çndice Gini del nuevo modelo exhibe un notable 74.3%, superando significativamente el 41.9% del modelo actual. Esta tendencia positiva se mantiene constante en otras cohortes, evidenciando un aumento considerable en la capacidad de discriminar el riesgo crediticio. Es especialmente notable el desempe√±o de los nuevos modelos en cohortes m√°s recientes, como la de diciembre de 2020, donde logra un √çndice Gini del 66.6% y 65.7%, en comparaci√≥n con el 36.9% del modelo actual.
# ` `<a name="_toc151738741"></a>8. An√°lisis de eficiencia energ√©tica 
En el proceso de evaluaci√≥n del consumo energ√©tico, es crucial destacar que el proyecto se llev√≥ a cabo en el entorno de PySpark debido a su alineaci√≥n con la infraestructura del servidor de riesgos en la empresa Alfa. La elecci√≥n de trabajar en PySpark tambi√©n estuvo condicionada por restricciones de seguridad que imped√≠an la extracci√≥n de informaci√≥n del proyecto para su ejecuci√≥n y medici√≥n de consumo en un entorno local. Estas restricciones, comunes en entornos empresariales, subrayaron la necesidad de realizar todas las etapas del proyecto directamente en el entorno proporcionado por la empresa.

Es importante se√±alar que el entorno de trabajo en PySpark est√° dise√±ado espec√≠ficamente para la ejecuci√≥n de tareas distribuidas y procesamiento masivo de datos. Aunque este enfoque ofrece grandes ventajas en t√©rminos de escalabilidad y eficiencia, presenta desaf√≠os particulares en la obtenci√≥n detallada de informaci√≥n sobre el consumo de energ√≠a. A pesar de que la medici√≥n directa del consumo de energ√≠a habr√≠a sido la opci√≥n preferida, la limitada disponibilidad de informaci√≥n detallada desde el entorno de PySpark motiv√≥ la elecci√≥n de m√©tricas alternativas, como el tiempo y la memoria, como indicadores pragm√°ticos para evaluar el rendimiento. Estas m√©tricas proporcionan una visi√≥n esencial del rendimiento computacional y son factores clave para evaluar la eficiencia de los modelos en un entorno distribuido.

Debido a lo anterior, no es posible medir directamente la energ√≠a. No obstante, s√≠ se pueden proporcionar detalles t√©cnicos sobre el entorno en el que trabajamos. Dependiendo de la talla asignada a cada usuario de riesgo, en nuestro **caso, trabajamos en la talla Py** durante el desarrollo.

![](039.png)

**Ilustraci√≥n 24:** Informaci√≥n t√©cnica de capacidad del servidor
## <a name="_toc151738742"></a>8.1 An√°lisis de eficiencia en modelado
Con el fin de evaluar el impacto del uso de diferentes herramientas en el consumo energ√©tico durante el entrenamiento del modelo, primero realizamos una evaluaci√≥n del tiempo y la memoria utilizados en estos procesos. Adem√°s, este mismo proceso se llev√≥ a cabo para el c√°lculo de las variables de grafo, dado que es un proceso iterativo que consume significativamente m√°s recursos que la construcci√≥n de otros tipos de variables que tambi√©n evaluamos.

### <a name="_toc151738743"></a>8.1.1 Gasto en tiempo
Para llevar a cabo la medici√≥n del tiempo de ejecuci√≥n, se registra la hora al iniciar la ejecuci√≥n del c√≥digo y posteriormente al finalizar la misma. De esta manera, calculamos la duraci√≥n en horas de la ejecuci√≥n y luego convertimos este valor a minutos para obtener una lectura m√°s precisa y comprensible.

|**Modelo**|**Horas**|**Segundos**|
| :-: | :-: | :-: |
|Variables de Grafo|6:04:23|364\.38|
|Regresi√≥n con grafo|0:47:56|47\.93|
|Regresi√≥n sin grafo|0:38:06|38\.10|
|Xgboost con grafo|3:16:42|196\.70|
|Xgboost sin grafo|2:51:15|171\.25|
|Ramdon con grafo|1:47:50|118\.23|
|Ramdon sin grafo|1:58:14|107\.83|

**Tabla 13:** Tiempo consumido en construcci√≥n de grafo y entrenamiento de modelos

### <a name="_toc151738744"></a>8.1.2 Gasto en Memoria
La m√©trica de memoria que consideramos en este caso es la memoria m√°xima utilizada durante la ejecuci√≥n del c√≥digo, ya sea durante el entrenamiento o la generaci√≥n de variables, seg√∫n corresponda al caso particular. Este dato se representa en megabytes (MB) de memoria consumida.

|**Modelo**|**Memoria (MB)**|
| :-: | :-: |
|Variables de Grafo|1728\.57|
|Regresi√≥n con grafo|5938\.77|
|Regresi√≥n sin  grafo|5898\.70|
|Xgboost con grafo|2959\.97|
|Xgboost sin grafo|2740\.59|
|Ramdon con grafo|2562\.27|
|Ramdon sin grafo|2517\.46|

**Tabla 14:** Memoria consumida en construcci√≥n de grafo y entrenamiento de modelos
## <a name="_toc151738745"></a>8.2 An√°lisis de eficiencia en producci√≥n
Debido a las restricciones iniciales de recursos en el entorno de PySpark proporcionado por ALFA, nuestro proyecto se vio obligado a trabajar con una muestra representativa de clientes. Para abordar el an√°lisis de la eficiencia energ√©tica en producci√≥n, llevamos a cabo mediciones de tiempos de ejecuci√≥n en los seis modelos previamente desarrollados. Estas mediciones abarcaron diferentes cantidades de clientes con el objetivo central de establecer relaciones entre la cantidad de registros, el tiempo de ejecuci√≥n y el consumo de memoria.

En cada uno de los seis modelos, aplicamos distintas aproximaciones matem√°ticas, que incluyeron modelos lineales, polin√≥micos de segundo grado, exponenciales y logar√≠tmicos. Evaluamos la idoneidad de estas aproximaciones mediante el coeficiente de determinaci√≥n (R¬≤) para seleccionar la funci√≥n que mejor se adaptara a los datos. Esto nos permiti√≥ estimar de manera precisa la utilizaci√≥n de memoria y el tiempo real necesario para la ejecuci√≥n de estos modelos en un entorno de producci√≥n.
### <a name="_toc151738746"></a>8.2.1 Gasto en tiempo y memoria
Como se mencion√≥ previamente, para obtener las funciones que relacionan el tiempo y la memoria con la cantidad de registros, segmentamos la muestra en diez partes, aumentando su tama√±o en un 10% en cada iteraci√≥n. Luego, cargamos el mejor modelo resultante de cada uno de los seis entrenamientos realizados en el proyecto y lo aplicamos a la muestra parcial para determinar el tiempo requerido para realizar predicciones sobre el nivel de incumplimiento. Cuyo resultado presentamos a continuaci√≥n:

![](040.png)

**Tabla 15:** Consumo de tiempo y memoria en la ejecuci√≥n de modelos con diferentes cantidades de clientes
### <a name="_toc151738747"></a>8.2.2 Estimaci√≥n de curvas
Una vez se complet√≥ el c√°lculo de los tiempos y la memoria consumida en cada muestra, se procedi√≥ a estimar las curvas que mejor representan el comportamiento del tiempo y la memoria en relaci√≥n con el tama√±o de la muestra. Este proceso se llev√≥ a cabo utilizando Microsoft Excel, donde se generaron gr√°ficos de dispersi√≥n para cada modelo y se evalu√≥ cu√°l de las curvas (logar√≠tmica, exponencial, polin√≥mica base dos o lineal) se ajustaba de manera √≥ptima a los datos. A continuaci√≥n, se presentan los resultados finales de las curvas seleccionadas y en el anexo 13 se detalla los datos y an√°lisis realizados
#### 8\.2.2.1 Xgboost
![](041.png)

![](042.png)
#### 8\.2.2.2 Random Forest
![](043.png)
#### 8\.2.2.3 Regresi√≥n Log√≠stica
![](044.png)

![](045.png)

#### 8\.2.2.4 Estimaci√≥n tiempo y memoria poblaci√≥n total
Como se detalla en el an√°lisis previo, en todos los casos, la estimaci√≥n polin√≥mica demostr√≥ el mejor ajuste a los datos. Sin embargo, la diferencia en rendimiento con la regresi√≥n log√≠stica es m√≠nima. Con el objetivo de prevenir un posible sobreajuste, se opt√≥ por utilizar la regresi√≥n log√≠stica para calcular el tiempo necesario para evaluar la probabilidad de incumplimiento de los clientes en la muestra completa. A continuaci√≥n, se presentan los resultados obtenidos:

![](046.png)

**Tabla 16:** Estimaci√≥n de tiempos en producci√≥n con poblaci√≥n total

Los resultados del tiempo total en segundo y la memoria en MB utilizada para la poblaci√≥n completa se detallan en la columna "y" en azul claro. Nuevamente, se confirma que el modelo que consume menos recursos es el XGBoost.
## <a name="_toc151738748"></a>8.3 Resultados
### <a name="_toc151738749"></a>8.3.1 Resultados en Entrenamiento
En el proceso de medici√≥n de eficiencia energ√©tica durante el entrenamiento de modelos, se obtuvieron resultados significativos. Las mediciones se centraron en evaluar el tiempo y la memoria utilizados en estos procesos, incluyendo el an√°lisis de las variables de grafo, que resultaron ser particularmente intensivas en recursos. En t√©rminos generales, los modelos de regresi√≥n, tanto con c√≥mo sin variables de grafo, demostraron un mejor rendimiento en cuanto a tiempos de entrenamiento en comparaci√≥n con Random Forest y XGBoost, pero tienen un mayor consumo de memoria ya que al trabajar en el algoritmo de regresi√≥n no se entrena en distribuido sino que se utiliza pandas lo que genera una mayor utilizaci√≥n de memoria.

Entre las t√©cnicas evaluadas, XGBoost fue la que requiri√≥ m√°s tiempo de entrenamiento, especialmente cuando se aplicaron variables de grafo. Por otro lado, las t√©cnicas de Regresi√≥n Log√≠stica, tanto con c√≥mo sin variables de grafo, destacaron por su eficiencia en t√©rminos de tiempo durante el proceso de entrenamiento. Sin embargo, al analizar los resultados predictivos en su conjunto, se observa una marcada diferencia en la capacidad predictiva entre la utilizaci√≥n de machine learning y su ausencia.

Es importante destacar que, en el caso de las variables de tipo grafo, su consumo en t√©rminos de recursos es a√∫n mayor que el del entrenamiento de algunos modelos, y no est√°n generando una ganancia predictoria significativa. Adem√°s, la generaci√≥n de estas variables deber√≠a realizarse en cada ejecuci√≥n del modelo, a diferencia del entrenamiento. Por lo tanto, no resulta sugerible su implementaci√≥n.

No obstante, es relevante se√±alar que, aunque en esta ocasi√≥n las redes no proporcionaron informaci√≥n altamente predictiva, el aumento en el uso de los canales digitales en el futuro podr√≠a permitir la creaci√≥n de redes con un mayor grado de relaci√≥n, ya que se conocer√≠a el origen y el destino de los datos. Por lo tanto, es posible que en el futuro se vuelva a analizar la incorporaci√≥n de este tipo de informaci√≥n en la predicci√≥n del riesgo, especialmente en segmentos m√°s espec√≠ficos y menos masivos, como las recuperaciones de cartera.
### <a name="_toc151738750"></a>8.3.2 Resultados en Producci√≥n
En conclusi√≥n, el an√°lisis de eficiencia en producci√≥n realizado en este proyecto ha arrojado resultados significativos que arrojan luz sobre la elecci√≥n y optimizaci√≥n de modelos en un entorno de PySpark. Las limitaciones iniciales de recursos, que nos llevaron a trabajar con muestras de diferentes tama√±os, proporcionaron informaci√≥n valiosa sobre la relaci√≥n entre el tiempo de ejecuci√≥n, la utilizaci√≥n de memoria y la cantidad de registros.

El modelo XGBoost (XGB) se destac√≥ por su consistente eficiencia en t√©rminos de tiempo de ejecuci√≥n en todas las muestras, manteniendo una utilizaci√≥n de memoria constante. Por otro lado, los modelos de Regresi√≥n Log√≠stica (RL) mostraron una previsibilidad en sus m√©tricas, aunque se observaron variaciones inusuales en el uso de memoria en ciertas situaciones. Los modelos de Bosques Aleatorios (RF) ofrecieron tiempos de ejecuci√≥n razonables, aunque consumieron m√°s memoria en comparaci√≥n con XGBoost.

Estos hallazgos respaldan la importancia de considerar tanto el tiempo de ejecuci√≥n como la utilizaci√≥n de memoria al seleccionar y optimizar modelos para la implementaci√≥n en producci√≥n. La elecci√≥n del modelo adecuado depender√° de los recursos disponibles y las necesidades espec√≠ficas del proyecto. En √∫ltima instancia, esta investigaci√≥n proporciona una base s√≥lida para la toma de decisiones informadas en la producci√≥n de modelos en un entorno de an√°lisis de datos.
### <a name="_toc151738751"></a>8.3.3 Resultados de eficiencia versus modelo actuales
En este punto, realizar una comparaci√≥n lineal de las mejoras entre el modelo actual y la propuesta del proyecto resulta desafiante, ya que no solo influye el cambio de metodolog√≠a, sino que tambi√©n implica un cambio tecnol√≥gico significativo dentro de la compa√±√≠a. El modelo actual no se ejecuta desde un entorno de inteligencia, sino que es un proceso manual que se lleva a cabo desde SAS Enterprise Manager, donde se han identificado deficiencias y definiciones manuales de modelos generados.

Teniendo en cuenta este contexto, el proceso actual de generaci√≥n del score en la cartera particular requiere aproximadamente 6 horas. Al validar los resultados de la proyecci√≥n del modelo XGBoost, se estima que el tiempo necesario para calificar con esta propuesta ser√≠a de aproximadamente 3 minutos, considerando la poblaci√≥n total. Este cambio dr√°stico en el tiempo de ejecuci√≥n resalta la eficiencia y la agilidad que aportar√≠a la implementaci√≥n de la nueva metodolog√≠a y tecnolog√≠a propuestas en el proyecto.
# <a name="_toc151738752"></a>9. Conclusiones
En este estudio, se llev√≥ a cabo la construcci√≥n de variables, el entrenamiento y la evaluaci√≥n de modelos de predicci√≥n de incumplimiento de clientes del banco Alfa que domiciliaban n√≥mina o pensi√≥n en el banco. Estos modelos fueron evaluados no solo en t√©rminos de eficiencia t√©cnica, sino tambi√©n en su consumo energ√©tico. Se emplearon t√©cnicas como la Regresi√≥n Log√≠stica, Random Forest y XGBoost, seleccionadas por cumplir con las regulaciones de la compa√±√≠a en cuanto a explicabilidad exigida por el ente regulador. Al final, XGBoost se destac√≥ como el modelo m√°s efectivo en predecir la probabilidad de incumplimiento de los clientes vinculados, gracias a su capacidad de aprendizaje y alto poder predictivo.

El estudio abarc√≥ la evaluaci√≥n de modelos tanto con c√≥mo sin variables de an√°lisis de redes, con el prop√≥sito de determinar su aporte significativo al modelo. Aunque se observ√≥ que estas variables podr√≠an mejorar la capacidad predictiva, su exclusi√≥n no generaba una p√©rdida sustancial de eficiencia, especialmente considerando el aumento en el costo computacional al aplicarlas en un contexto de granularidad tan alta como las transacciones bancarias. No obstante, se recomienda considerar este tipo de an√°lisis en otros tipos de clientes, como los empresariales, donde los conjuntos de datos son m√°s peque√±os y han demostrado ser exitosos en la literatura.

Una de las razones por las cuales el estudio de redes no parece aportar un valor significativo en la mejora del poder predictivo del modelo es que, al detallar las relaciones de los actores en la red, se observ√≥ que eran pocos los casos donde los actores se relacionaban con varios nodos; la mayor√≠a no interactuaba con otros clientes, por lo cual no se encontraba esta sinergia que aporta valor en el An√°lisis de Redes Sociales (SNA, por sus siglas en ingl√©s). Sin embargo, no se debe descartar su inclusi√≥n en el futuro, ya que estos datos est√°n sujetos a un periodo temporal en el cual el banco no contaba con una app m√≥vil que facilitara los movimientos de dinero entre personas. Este escenario cambi√≥ en marzo de 2023 con el lanzamiento de la nueva app m√≥vil, y ya se observa un aumento en el uso de canales web en el banco. Tambi√©n es relevante destacar que, seg√∫n estudios en la literatura de SNA, estas variables tienden a tener m√°s poder en entornos empresariales, por lo que se recomienda realizar el an√°lisis con modelos orientados a este tipo de clientes.

En t√©rminos de consumo de recursos, se obtuvieron valiosas conclusiones tanto en el entrenamiento como en la implementaci√≥n. Se destac√≥ que la Regresi√≥n Log√≠stica era menos costosa en tiempo en comparaci√≥n con Random Forest y XGBoost, pero con un mayor uso de memoria debido a su entrenamiento no distribuido. Asimismo, se observ√≥ que las variables de grafo, aunque intensivas en recursos, no aportaron una ganancia significativa en la capacidad predictiva, lo que sugiere su no implementaci√≥n. No obstante, se vislumbra la posibilidad de considerar su uso en el futuro, dada la tendencia al aumento en el uso de canales digitales. En resumen, XGBoost se posiciona como la mejor opci√≥n de implementaci√≥n tanto por eficiencia energ√©tica como por poder predictivo, pero es importante recordar que estos resultados son v√°lidos en contextos similares a los abordados en este estudio, donde se acotan la cantidad de variables finales del modelo, ya que en escenarios sin esta limitaci√≥n, las t√©cnicas de machine learning tienden a ser m√°s costosas en recursos.
# <a name="_toc512935112"></a><a name="_toc151738753"></a>10. Recepci√≥n del negocio
<a name="_toc428793033"></a>Este trabajo tambi√©n fue presentado a la organizaci√≥n durante su desarrollo, contando con el acompa√±amiento del manager de modelos de riesgos. Este colaborador proporcion√≥ valioso feedback sobre las condiciones de negocio y los requisitos t√©cnicos que el modelo en producci√≥n deb√≠a cumplir. Es importante destacar que el proceso formal de desarrollo del nuevo modelo de scoring comportamental en el banco ya se ha iniciado. Este desarrollo comenz√≥ a principios de septiembre, y se espera que se entregue al comit√© en junio de 2024. La decisi√≥n de tomar como base los resultados de este modelo para iniciar el desarrollo refleja la confianza en su viabilidad y relevancia.

En relaci√≥n con la implementaci√≥n del nuevo modelo comportamental, se optar√° por utilizar XGBoost como herramienta de predicci√≥n. No se utilizar√° el mismo modelo que ya se gener√≥ por tres razones fundamentales. En primer lugar, se busca incorporar todos los segmentos de clientes dentro del modelo, no limit√°ndose solo a los clientes vinculados. En segundo lugar, se cambiar√° la ventana temporal de evaluaci√≥n, aprovechando la disponibilidad de la informaci√≥n completa de 2022. La generaci√≥n de m√©tricas se llevar√° a cabo entre 2020 y 2021, con observaci√≥n en 2022. Como tercer motivo, se incorporar√°n otras fuentes de informaci√≥n desarrolladas por el √°rea de client solution. Estas fuentes incluyen variables relacionadas con la huella digital de los clientes y variables de advice que indican las categor√≠as de productos m√°s adquiridas por los clientes del banco.
# <a name="_toc151738754"></a>11. Trabajos futuros
En el horizonte de trabajos futuros, se vislumbran diversas oportunidades para mejorar y expandir la eficacia de los modelos desarrollados. Se sugiere explorar una colaboraci√≥n activa con el √°rea de ingenier√≠a para llevar a cabo mediciones detalladas del consumo energ√©tico asociado a distintas t√©cnicas de machine learning. Esta iniciativa permitir√° obtener una comprensi√≥n m√°s precisa del impacto ambiental de las operaciones de modelado, respaldando as√≠ decisiones basadas en criterios de sostenibilidad.

Adem√°s, se plantea la necesidad de actualizar los modelos existentes para abarcar otros segmentos de clientes, proporcionando una visi√≥n m√°s completa del comportamiento crediticio en toda la base de clientes. Asimismo, se propone la optimizaci√≥n de los hiperpar√°metros del modelo XGBoost mediante herramientas de optimizaci√≥n autom√°tica como AutoGluon, con el objetivo de potenciar a√∫n m√°s su rendimiento.

En el √°mbito de la mejora de los modelos, se destaca la importancia de explorar t√©cnicas de descarte de variables, como Recursive Feature Importance (RFI) y Recursive Feature Elimination (RFE), para refinar el conjunto de variables predictoras y fortalecer la eficiencia y la capacidad predictiva del modelo.

La implementaci√≥n exitosa del nuevo modelo en el entorno de producci√≥n se presenta como un paso crucial. Garantizar una transici√≥n suave y eficiente del modelo desarrollado al entorno operativo es esencial para aprovechar plenamente los beneficios del nuevo enfoque.

Para ampliar la comprensi√≥n del riesgo crediticio en diferentes contextos, se propone extender el an√°lisis de redes a segmentos empresariales. Evaluando c√≥mo las interacciones entre clientes impactan el riesgo crediticio en este contexto espec√≠fico, se puede obtener una perspectiva m√°s completa y detallada.

Finalmente, se sugiere realizar una evaluaci√≥n exhaustiva del impacto ambiental de los modelos actuales, considerando factores como el consumo energ√©tico y otros recursos. Este an√°lisis contribuir√° a una mayor conciencia de la sostenibilidad de las operaciones de modelado en el contexto empresarial y proporcionar√° informaci√≥n valiosa para posibles ajustes futuros.
# <a name="_toc151738755"></a>Bibliograf√≠a
Abdulsalam, S., Lakomski, D., Qijun, G., Tongdan, J., & Zong, Z. (2015). Program Energy Efficiency: The Impact of Language, Compiler and Implementation Choices. *International Green Computing Conference*, 03-05.

ALFA. (2021). *Informe Individual Colombia 2021*. Obtenido de file:///C:/Users/c805821/Documents/Tesis/Informe-individual-mar22.pdf

ALFA. (2022). *Informacion Corporativa*. Obtenido de Carta del presidente: https://www.alfa.com/es/informacion-corporativa/#carta-presidente

Amazon Web Services. (5 de Mayo de 2023). *Aws & sustainability*. Obtenido de https://aws.amazon.com/es/industrial/sustainability/

Andrade, F., & Sics√∫, A. (2008). A credit risk model for consumer loan portfolios. *Latin American Business*, 75-91.

Asobancaria. (2021). *Marco jur√≠dico del sector financiero colombiano*. Obtenido de http://www.asobancaria.com/portal/page/portal/Asobancaria/publicaciones/juridico_legal/marco_juridico_del_sector_financiero_colombiano/estructura_del_sector_financiero/

Boz, Z., Gunnec, D., Birbil, S., & √ñzt√ºrk, M. (2018). Reassessment and monitoring of loan. *Applied Artificial Intelligence*, 09-10.

Chitarroni, H. (2022). La regresi√≥n log√≠stica. *Instituto de Investigaci√≥n en Ciencias Sociales*, 1-8.

Dandres, T., Schmidt, V., Luccioni, A., & Lacoste, A. (2019). Quantifying the Carbon Emissions of Machine Learning. *Computers and Society*. Obtenido de https://arxiv.org/pdf/1910.09700.pdf

Deepanshu, B. (28 de 07 de 2023). *Listen data*. Obtenido de WEIGHT OF EVIDENCE (WOE) AND INFORMATION VALUE (IV) EXPLAINED: https://www.listendata.com/2015/03/weight-of-evidence-woe-and-information.html

Eggleston, S., Buendia, L., Miwa, K., Ngara, T., & Tanabe, K. (2006). IPCC guidelines for national greenhouse gas inventories. *Institute for Global Environmental Strategies Hayama*.

El Tiempo. (2017). *As√≠ lo califican los bancos como buena o mala paga*. Obtenido de https://www.eltiempo.com/economia/finanzas-personales/categoria-para-la-calificacion-de-los-usuarios-que-aspiran-a-un-credito-106818

Escuela Nacional Sindical. (2015). *Sector Financiero Y Bancario Colombiano Caracter√≠s-ticas Econ√≥micas, Laborales y de Negociaci√≥n Colectiva*. Obtenido de http://www.ens.org.co/wp-content/uploads/2016/12/DOCUMENTOS-DE-LA-ESCUELA_100-Sector-financiero-y-bancario-colombiano-Econ%C3%B3mico-laboral-y-de-negociaci%C3%B3n-colectiva-2015.pdf

Experian. (Septiembre de 2022). *RESUMEN EJECUTIVO ALFA 2022*. Obtenido de https://drive.google.com/file/d/11hQ9_YmxcDYvtVVpIqpVqg-r_pWcajAT/view?usp=sharing

Hindistan, Y., Aiyakogu, B., Rezaeinazhad, A., Korkmaz, H., & Dag, H. (2019). Alternative credit scoring and classification employing machine learning techniques on a big data. *International Conference on Computer Science and Engineering*, 1-4.

Jackson, M. (2010). Social and Economic Networks. *Princeton University Press*.

Jian, L., Haibin, L., Zhijun, Y., & Lei, H. (2021). A Credit Risk Model with Small Sample Data Based on G-XGBoost. *APPLIED ARTIFICIAL INTELLIGENCE, 35*(15), 1550-1566.

Kruppa, J., Schwarz, A., Arminger, G., & Ziegler, A. (2013). Consumer credit risk: Individual probability estimates using machine learning. *Expert Systems with Applications*, 25-31.

Li, Y. (2019). Credit risk prediction based on machine learning methods. *International Conference on Computer Science & Education*, 11-13.

Liu, Z., Huang, G., & Xie, L. (2019). Is risk management with big data effective? Comparison and analysis based on statistics score card and machine learning model. *Statistics & Information Forum*, 18-26.

Luo, C., Wu, D., & Wu, D. (2016). A deep learning approach for credit scoring using credit default swaps. *Engineering Applications of Artificial Intelligence*, 65.

Nedellec, C., Correira, J., Ferreira, J., & Costa, E. (1994). Machine learning goes to the bank. *Applied Artificial Intelligence*, 593-615.

Omar Y, A.-J., Paul D, Y., Sami, M., George, K., & Kamal, T. (2015). Efficient Machine Learning for Big Data: A Review. *Big Data Research*, 87-93.

Oriol, A. (2014). *Scoring y rating. C√≥mo se elaboran e interpretan*. Obtenido de http://www.supercontable.com/envios/articulos/BOLETIN_AVENIDA_02_2014_Articulo_2.htm

√ìskarsd√≥ttir, M., & Bravo, C. (Diciembre de 2021). Multilayer network analysis for improved credit risk prediction. *Omega, 105*, 102520. Obtenido de https://www.sciencedirect.com/science/article/abs/pii/S0305048321001298?via%3Dihub

Ospina D√≠az, N. (2017). Scoring: un reto del mundo Fintech. *PORTAFOLIO*.

Qiu, W. (2019). Credit risk prediction in an imbalanced social lending environment based on XGBoost. *International Conference on Big Data and Information Analytics*, 50-56.

Rishehchi Fayyaz, M., R. Rasouli, M., & Amiri, B. (2021). A data-driven and network-aware approach for credit risk prediction in supply chain finance. *Industrial Management & Data y Systems*, 785-808.

Shukla, U., & Nanda, S. (2019). Designing of a risk assessment model for issuing credit card using parallel social spider algorithm. *Applied Artificial Intelligence*, 191-207.

Tran, K., Duong, T., & Ho, Q. (2016). A combination of genetic programming and deep learning. *Future Technologies Conference*, 45-49.

Wang, C., Xu, C., Yao, X., & Tao, D. (2019). Evolutionary generative adversarial networks. *IEEE Transactions on Evolutionary Computation.* .

Wang, H., Zhong, J., Zhang, F., & Zou, X. (2017). A new classification algorithm for the bank customer credit rating. *Ninth International Conference on Advanced Computational Intelligence*, 43-48.

Wasserman, S., & Faust, K. (1994). *Social Network Analysis.* United States: Cambridge University Press.

Zhang, D., Huang, H., Chen, Q., & Jiang, Y. (2007). A comparison study of credit scoring models. *Third International Conference of Natural Computation*.


